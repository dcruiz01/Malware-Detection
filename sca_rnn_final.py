# dependencies
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential, load_model, Model
from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, InputLayer
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, Callback
from tensorflow.keras.optimizers import RMSprop

'''
Model Codes:
1-Vanilla RNN
2-LSTM
3-Bidirectional LSTM
4-GRU
5-Bidirectional GRU
'''

# global variables
SEQUENCE_LENGTHS = [1,5,20,40,80,160,320,640,960] # 500ms capture rate
model_type = 5
train_datapath = 'data_blend/train'
test_datapath = 'data_blend/test'

def prepare_data(datapath, seqlen):

    # read in data
    frames = []
    numfiles = 0
    for data_file in os.scandir(datapath):
        if (data_file.path.endswith('.csv') and data_file.is_file()):
            numfiles += 1
            df = pd.read_csv(data_file)
            df_cutoff = df[:df.shape[0] - df.shape[0] % seqlen].copy() # remove rows to ensure no sequences span two files
            print(f'Removed {df.shape[0] - df_cutoff.shape[0]} rows from {data_file.path}, Original Size: {df.shape[0]}')
            frames.append(df_cutoff)
    print(f'Number of files processed: {numfiles}')

    # concatenate all data into a single dataframe
    df_big = pd.concat(frames)

    # remove unneeded features 
    dropped_columns = ['Date', 'Time', 'OS', 'machine', 'activity'] # 'Label' column removed after label vector creation
    df_big.drop(columns = dropped_columns, inplace = True)

    # convert Yes/No columns to 1/0
    df_big.replace(['Yes', 'No'], ['1.0', '0.0'], inplace = True)

    # convert all values to float
    df_big = df_big.astype(float)

    # generate labels
    labels = []
    for i in range(0, len(df_big), seqlen):
        block = df_big['Label'][i:i+seqlen]
        if 1.0 in block:
            labels.append(1)
        else:
            labels.append(0)

    # convert labels to numpy array
    labels = np.array(labels)

    # remove 'Label' column
    df_big.drop(columns = 'Label', inplace = True)

    # convert data to numpy array
    data = np.array(df_big.to_numpy(dtype = 'float32'))
    data = data.reshape(-1, seqlen, 116) # reshape based on sequence length

    return data, labels

def create_model(seqlen, T):
    M = Sequential()
    if T == 1:
        M.add(SimpleRNN(16, input_shape = (seqlen,116), return_sequences = True))
        M.add(SimpleRNN(32, return_sequences = True))
        M.add(SimpleRNN(32, return_sequences = True))
        M.add(SimpleRNN(16))
    elif T == 2:
        M.add(LSTM(16, input_shape = (seqlen,116), return_sequences = True))
        M.add(LSTM(32, return_sequences = True))
        M.add(LSTM(32, return_sequences = True))
        M.add(LSTM(16))
    elif T == 3:
        M.add(Bidirectional(LSTM(16, return_sequences = True), input_shape = (seqlen, 116)))
        M.add(Bidirectional(LSTM(32, return_sequences = True)))
        M.add(Bidirectional(LSTM(32, return_sequences = True)))
        M.add(Bidirectional((LSTM(16))))
    elif T == 4:
        M.add(GRU(16, input_shape = (seqlen,116), return_sequences = True))
        M.add(GRU(32, return_sequences = True))
        M.add(GRU(32, return_sequences = True))
        M.add(GRU(16))
    elif T == 5:
        M.add(Bidirectional(GRU(16, return_sequences = True), input_shape = (seqlen,116)))
        M.add(GRU(32, return_sequences = True))
        M.add(GRU(32, return_sequences = True))
        M.add(GRU(16))
    M.add(Dense(1, activation = 'sigmoid'))
    M.compile(loss = 'binary_crossentropy', optimizer = RMSprop(lr = .001), metrics = ['accuracy'])
    return M

with open(f'RNN_log_{model_type}.txt', 'a') as out_file:

    for i in SEQUENCE_LENGTHS:

        # Generate training & test sets
        xtrain, ytrain = prepare_data(train_datapath, i)
        xtest, ytest = prepare_data(test_datapath, i)
        print(xtrain.shape, ytrain.shape, xtest.shape, ytest.shape)

        # Create model
        print(f'Creating type {model_type} model.', file = out_file)
        model = create_model(i, model_type)

        # Callback list
        A = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 10, min_delta = .0001, restore_best_weights=True)
        B = ModelCheckpoint(filepath = 'models/RNN/RNN_model.hdf5', save_best_only = True, verbose = 1, monitor = 'val_loss', mode = 'min', )
        C = ReduceLROnPlateau(monitor = 'val_loss', factor = .1, patience = 10, verbose = 1, min_delta = .001)

        cb_list = [A, B, C]

        # Fit model
        print(f'Training with sequence length: {i}', file = out_file)
        history = model.fit(xtrain, ytrain, validation_split = .10, shuffle = True, batch_size = 16, epochs = 100, verbose = 1, callbacks = cb_list)

        # Evaluate on test data
        trained_model = load_model('models/RNN/RNN_model.hdf5')
        results = trained_model.evaluate(xtest, ytest, batch_size = 16, verbose = 1)
        print(f'test loss, test acc: {results}', file = out_file)