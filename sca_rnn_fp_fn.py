# dependencies
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential, load_model, Model
from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, InputLayer
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, Callback
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.metrics import FalsePositives, FalseNegatives, BinaryAccuracy

# global variables
SEQUENCE_LENGTH = 960 # 500ms capture rate
model_type = 4
METRICS = [FalsePositives(name='fp'), FalseNegatives(name='fn'), BinaryAccuracy(name='accuracy')]
train_datapath = 'data_blend/train'
test_datapath = 'data_blend/test'

def prepare_data(datapath, seqlen):

    # read in data
    frames = []
    numfiles = 0
    for data_file in os.scandir(datapath):
        if (data_file.path.endswith('.csv') and data_file.is_file()):
            numfiles += 1
            df = pd.read_csv(data_file)
            df_cutoff = df[:df.shape[0] - df.shape[0] % seqlen].copy() # remove rows to ensure no sequences span two files
            print(f'Removed {df.shape[0] - df_cutoff.shape[0]} rows from {data_file.path}, Original Size: {df.shape[0]}')
            frames.append(df_cutoff)
    print(f'Number of files processed: {numfiles}')

    # concatenate all data into a single dataframe
    df_big = pd.concat(frames)

    # remove unneeded features 
    dropped_columns = ['Date', 'Time', 'OS', 'machine', 'activity'] # 'Label' column removed after label vector creation
    df_big.drop(columns = dropped_columns, inplace = True)

    # convert Yes/No columns to 1/0
    df_big.replace(['Yes', 'No'], ['1.0', '0.0'], inplace = True)

    # convert all values to float
    df_big = df_big.astype(float)

    # generate labels
    labels = []
    for i in range(0, len(df_big), seqlen):
        block = df_big['Label'][i:i+seqlen]
        if 1.0 in block:
            labels.append(1)
        else:
            labels.append(0)

    # convert labels to numpy array
    labels = np.array(labels)

    # remove 'Label' column
    df_big.drop(columns = 'Label', inplace = True)

    # convert data to numpy array
    data = np.array(df_big.to_numpy(dtype = 'float32'))
    data = data.reshape(-1, seqlen, 116) # reshape based on sequence length

    return data, labels

def create_model(seqlen, T, mets):
    M = Sequential()
    if T == 1:
        M.add(SimpleRNN(16, input_shape = (seqlen,116), return_sequences = True))
        M.add(SimpleRNN(32, return_sequences = True))
        M.add(SimpleRNN(32, return_sequences = True))
        M.add(SimpleRNN(16))
    elif T == 2:
        M.add(LSTM(16, input_shape = (seqlen,116), return_sequences = True))
        M.add(LSTM(32, return_sequences = True))
        M.add(LSTM(32, return_sequences = True))
        M.add(LSTM(16))
    elif T == 3:
        M.add(Bidirectional(LSTM(16, return_sequences = True), input_shape = (seqlen, 116)))
        M.add(Bidirectional(LSTM(32, return_sequences = True)))
        M.add(Bidirectional(LSTM(32, return_sequences = True)))
        M.add(Bidirectional((LSTM(16))))
    elif T == 4:
        M.add(GRU(16, input_shape = (seqlen,116), return_sequences = True))
        M.add(GRU(32, return_sequences = True))
        M.add(GRU(32, return_sequences = True))
        M.add(GRU(16))
    elif T == 5:
        M.add(Bidirectional(GRU(16, return_sequences = True), input_shape = (seqlen,116)))
        M.add(GRU(32, return_sequences = True))
        M.add(GRU(32, return_sequences = True))
        M.add(GRU(16))
    M.add(Dense(1, activation = 'sigmoid'))
    M.compile(loss = 'binary_crossentropy', optimizer = RMSprop(lr = .001), metrics = mets)
    return M

# Generate training & test sets
xtrain, ytrain = prepare_data(train_datapath, SEQUENCE_LENGTH)
xtest, ytest = prepare_data(test_datapath, SEQUENCE_LENGTH)
print(xtrain.shape, ytrain.shape, xtest.shape, ytest.shape)

# Create model
model = create_model(SEQUENCE_LENGTH, model_type, METRICS)

# Callback list
A = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 10, min_delta = .0001, restore_best_weights=True)
B = ModelCheckpoint(filepath = 'models/RNN/RNN_model.hdf5', save_best_only = True, verbose = 1, monitor = 'val_loss', mode = 'min', )
C = ReduceLROnPlateau(monitor = 'val_loss', factor = .1, patience = 10, verbose = 1, min_delta = .001)

cb_list = [A, B, C]

# Fit model
history = model.fit(xtrain, ytrain, validation_split = .10, shuffle = True, batch_size = 16, epochs = 100, verbose = 1, callbacks = cb_list)

# Evaluate on test data
trained_model = load_model('models/RNN/RNN_model.hdf5')
results = trained_model.evaluate(xtest, ytest, batch_size = 16, verbose = 1)
for name, value in zip(model.metrics_names, results):
  print(name, ': ', value)